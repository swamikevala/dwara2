package org.ishafoundation.dwaraapi.job;

import java.time.LocalDateTime;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;

import org.ishafoundation.dwaraapi.db.attributeconverter.enumreferences.StoragetaskAttributeConverter;
import org.ishafoundation.dwaraapi.db.cache.manager.DBMasterTablesCacheManager;
import org.ishafoundation.dwaraapi.db.dao.master.jointables.ActionelementDao;
import org.ishafoundation.dwaraapi.db.dao.transactional.JobDao;
import org.ishafoundation.dwaraapi.db.model.cache.CacheableTablesList;
import org.ishafoundation.dwaraapi.db.model.master.jointables.Actionelement;
import org.ishafoundation.dwaraapi.db.model.transactional.Job;
import org.ishafoundation.dwaraapi.db.model.transactional.Request;
import org.ishafoundation.dwaraapi.db.model.transactional.Subrequest;
import org.ishafoundation.dwaraapi.db.model.transactional.Volume;
import org.ishafoundation.dwaraapi.db.model.transactional.domain.Artifact;
import org.ishafoundation.dwaraapi.enumreferences.Action;
import org.ishafoundation.dwaraapi.enumreferences.Status;
import org.ishafoundation.dwaraapi.enumreferences.Storagetask;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

@Component
public class JobCreator {
	
	private static final Logger logger = LoggerFactory.getLogger(JobCreator.class);

	@Autowired
	private JobDao jobDao;
	
	@Autowired
	private ActionelementDao actionelementDao;
	
	
	
	@Autowired
	private StoragetaskAttributeConverter storagetaskAttributeConverter;

	@SuppressWarnings("rawtypes")
	@Autowired
	private DBMasterTablesCacheManager dBMasterTablesCacheManager;

	
	// only if action is async create job should be called...
	public List<Job> createJobs(Request request, Subrequest subrequest, Artifact artifact) throws Exception{
		Action requestedBusinessAction = request.getAction();

		org.ishafoundation.dwaraapi.db.model.master.reference.Action action = (org.ishafoundation.dwaraapi.db.model.master.reference.Action) dBMasterTablesCacheManager.getRecord(CacheableTablesList.action.name(), requestedBusinessAction.name());
		
		if(action == null)
			throw new Exception("Action for " + requestedBusinessAction.name() + " not configured in DB properly. Please set it first");
		
		Map<Integer, Job> actionelementId_Job_Map = new HashMap<>();
		
		List<Job> jobList = new ArrayList<Job>();
		if(!action.isAsync()) // No jobs are created for synchronous actions...
			return jobList; // should this be null or an empty list
		
		Storagetask storagetask = action.getStoragetask();
		if(action.isComplex()) {
			
			List<Actionelement> actionelementList = actionelementDao.findAllByActionAndArtifactclassIdOrderByDisplayOrderAsc(requestedBusinessAction, artifact.getArtifactclass().getId());
			for (Iterator<Actionelement> iterator = actionelementList.iterator(); iterator.hasNext();) {
				Actionelement actionelement = (Actionelement) iterator.next();
				
				int storagetaskId = actionelement.getStoragetaskId();
				int processingtaskId = actionelement.getProcessingtaskId();
			
				Job job = new Job();
				if(storagetaskId > 0)
					job.setStoragetaskId(storagetaskId);
				if(processingtaskId > 0)
					job.setProcessingtaskId(processingtaskId);
				
				if(actionelement.getActionelementRefId() != null) {
					job.setJobRef(actionelementId_Job_Map.get(actionelement.getActionelementRefId()));
				}
					
				
				// If a task contains prerequisite task that means its a derived one, for which the input library id needs to set by the prerequisite/parent task's job at the time of its processing and not at the time of job creation...
				// for eg., Mezz copy wont have a input library id upfront, which will be generated by its prerequisite/parent Mezz Transcoding job...
				else  {
					job.setInputArtifactId(artifact.getId());
				}
				job.setActionelement(actionelement);
				job.setSubrequest(subrequest);				
				job.setCreatedAt(LocalDateTime.now());
				job.setStatus(Status.queued);
				job = saveJob(job);
				jobList.add(job);
				actionelementId_Job_Map.put(actionelement.getId(), job);
			}
		}
		else {
			if(storagetask != null)
				jobList.addAll(createStorageTaskJobs(requestedBusinessAction, subrequest, storagetask));
		}
		return jobList;
	}
	
	private List<Job> createStorageTaskJobs(Action requestedBusinessAction, Subrequest subrequest, Storagetask storagetask){
		List<Job> simpleStoragetaskJobs = new ArrayList<Job>();
		Job job = new Job();
		
		int storagetaskId = storagetaskAttributeConverter.convertToDatabaseColumn(storagetask);
		job.setStoragetaskId(storagetaskId);
		job.setSubrequest(subrequest);
		// TODO needed only for sub actions - job.setInputArtifactId(subrequest.getDetails().getArtifact_id());
		job.setCreatedAt(LocalDateTime.now());
		job.setStatus(Status.queued);
		if(requestedBusinessAction == Action.restore) {
			Volume volume = null;
			//getvolume related stuff from the file here...
			job.setVolume(volume);
		}
		job = saveJob(job);
		simpleStoragetaskJobs.add(job);

		return simpleStoragetaskJobs;
	}
	
	
	private Job saveJob(Job job) {
		logger.debug("DB Job row Creation");   
		job = jobDao.save(job);
		logger.debug("DB Job row Creation - Success");
		return job;
	}

}
	
