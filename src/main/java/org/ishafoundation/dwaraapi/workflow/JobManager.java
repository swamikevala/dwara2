package org.ishafoundation.dwaraapi.workflow;

import java.util.ArrayList;
import java.util.Calendar;
import java.util.Iterator;
import java.util.List;

import org.ishafoundation.dwaraapi.constants.Status;
import org.ishafoundation.dwaraapi.db.dao.master.workflow.TaskDao;
import org.ishafoundation.dwaraapi.db.dao.master.workflow.TaskTasksetDao;
import org.ishafoundation.dwaraapi.db.dao.transactional.JobDao;
import org.ishafoundation.dwaraapi.db.dao.transactional.RequestDao;
import org.ishafoundation.dwaraapi.db.model.master.workflow.Task;
import org.ishafoundation.dwaraapi.db.model.master.workflow.TaskTaskset;
import org.ishafoundation.dwaraapi.db.model.transactional.Job;
import org.ishafoundation.dwaraapi.db.model.transactional.Library;
import org.ishafoundation.dwaraapi.db.model.transactional.Request;
import org.ishafoundation.dwaraapi.model.TaskOrTasksetDetails;
import org.ishafoundation.dwaraapi.process.thread.executor.ProcessSingleThreadExecutor;
import org.ishafoundation.dwaraapi.process.thread.executor.StorageSingleThreadExecutor;
import org.ishafoundation.dwaraapi.process.thread.task.ProcessJobManager_ThreadTask;
import org.ishafoundation.dwaraapi.storage.thread.task.StorageJobsManager_ThreadTask;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.ApplicationContext;
import org.springframework.stereotype.Component;

@Component
public class JobManager {
	
	private static final Logger logger = LoggerFactory.getLogger(JobManager.class);
	
	@Autowired
	private TaskTasksetDao taskTasksetDao;	
	
	@Autowired
	private JobDao jobDao;	

	@Autowired
	private RequestDao requestDao;

	@Autowired
	private TaskDao taskDao;
	
	@Autowired
	private JobUtils jobUtils;	

	@Autowired
	private TaskUtils taskUtils;
	
	@Autowired
	private ProcessSingleThreadExecutor processSingleThreadExecutor;
	
	@Autowired
	private StorageSingleThreadExecutor storageSingleThreadExecutor;

	@Autowired
	private ApplicationContext applicationContext;
	
	//createJobsForRestore
	//createJobsForRerunIngest
	public List<Job> createJobsForIngest(Request request, Library library){
		List<Job> jobList = new ArrayList<Job>();
		int requestId = request.getRequestId();

		TaskOrTasksetDetails taskOrTasksetDetails = taskUtils.getTaskOrTasksetDetails(request);
		int tasksetId = taskOrTasksetDetails.getTasksetId();
		int taskId = taskOrTasksetDetails.getTaskId();

		List<TaskTaskset> taskTasksetList = null;
		if(tasksetId > 0) {
			logger.trace("Its a taskset. tasksetId - " + tasksetId);
			taskTasksetList = taskTasksetDao.findAllByTasksetId(tasksetId);
			for (Iterator<TaskTaskset> iterator = taskTasksetList.iterator(); iterator.hasNext();) {
				TaskTaskset taskTaskset = (TaskTaskset) iterator.next();
				
				Job job = new Job();
				int taskId2 = taskTaskset.getTaskId();
				logger.trace("nthTaskId - " + taskId2);
				job.setTaskId(taskId2);
				// If a task contains prerequisite task that means its a derived one, for which the input library id needs to set by the prerequisite task...
				// for eg., Mezz copy wont have a library id  upfront, which will be generated by the Mezz Transcoding job...
				if(taskTaskset.getPreTaskId() == 0)
					job.setInputLibraryId(library.getLibraryId());
				job.setRequestId(requestId);				
				job.setCreatedAt(Calendar.getInstance().getTimeInMillis());
				job.setStatusId(Status.QUEUED.getStatusId());
				jobList.add(job);
			}
		}else if(taskId > 0){
			logger.trace("Its just a task. taskId - " + taskId); // not needed for ingest code
		}
		
		return jobList;
	}
	

	
	
	public void processJobs() {
		List<Job> storageJobList = new ArrayList<Job>();
		
		List<Job> jobList = jobDao.findAllByStatusIdOrderByJobId(Status.QUEUED.getStatusId());
		for (Iterator<Job> iterator = jobList.iterator(); iterator.hasNext();) {
			Job job = (Job) iterator.next();
			logger.info("job - " + job.getJobId());
			int taskId = job.getTaskId();
			int requestId = job.getRequestId();
			Request request = requestDao.findById(requestId).get(); // TODO : Cache the call...
			// check prerequisite jobs completion status
			boolean isJobReadyToBeProcessed = isJobReadyToBeProcessed(job, request);
			logger.info("isJobReadyToBeProcessed - " + isJobReadyToBeProcessed);
			if(isJobReadyToBeProcessed) {
				Task task = taskDao.findById(taskId).get();
				int processId = task.getProcessId();
				
				if(processId > 0) { // a non-storage process job
					logger.trace("process job");
					ProcessJobManager_ThreadTask processJobManager_ThreadTask = applicationContext.getBean(ProcessJobManager_ThreadTask.class);
					processJobManager_ThreadTask.setJob(job);
					processJobManager_ThreadTask.setProcessId(processId);
					processSingleThreadExecutor.getExecutor().execute(processJobManager_ThreadTask);
				}else {
					logger.trace("added to storagejob collection");
					// all storage jobs need to be grouped for some optimisation...
					storageJobList.add(job);
				}
			}
		}
		
		StorageJobsManager_ThreadTask storageThreadTask = applicationContext.getBean(StorageJobsManager_ThreadTask.class);
		storageThreadTask.setJobList(storageJobList);
		storageSingleThreadExecutor.getExecutor().execute(storageThreadTask);
	}

	private boolean isJobReadyToBeProcessed(Job job, Request request) {
		boolean isJobReadyToBeProcessed = true;
		
		Job parentJob = jobUtils.getPrerequisiteJob(job, request); // Has the prerequisite job's status is complete?
		if(parentJob != null) {
			int parentJobStatusId = parentJob.getStatusId();
			if(parentJobStatusId != Status.COMPLETED.getStatusId() && parentJobStatusId != Status.COMPLETED_WITH_FAILURE.getStatusId())
				isJobReadyToBeProcessed = false;
		}
		
		return isJobReadyToBeProcessed;
	}
}
