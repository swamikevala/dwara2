package org.ishafoundation.dwaraapi.job;

import java.time.LocalDateTime;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;

import org.ishafoundation.dwaraapi.constants.Status;
import org.ishafoundation.dwaraapi.db.dao.master.TaskDao;
import org.ishafoundation.dwaraapi.db.dao.master.jointables.TaskTasksetDao;
import org.ishafoundation.dwaraapi.db.dao.transactional.JobDao;
import org.ishafoundation.dwaraapi.db.dao.transactional.RequestDao;
import org.ishafoundation.dwaraapi.db.dao.transactional.SubrequestDao;
import org.ishafoundation.dwaraapi.db.model.master.Task;
import org.ishafoundation.dwaraapi.db.model.master.jointables.TaskTaskset;
import org.ishafoundation.dwaraapi.db.model.transactional.Job;
import org.ishafoundation.dwaraapi.db.model.transactional.Library;
import org.ishafoundation.dwaraapi.db.model.transactional.Request;
import org.ishafoundation.dwaraapi.db.model.transactional.Subrequest;
import org.ishafoundation.dwaraapi.process.thread.executor.ProcessSingleThreadExecutor;
import org.ishafoundation.dwaraapi.process.thread.executor.StorageSingleThreadExecutor;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.ApplicationContext;
import org.springframework.stereotype.Component;

@Component
public class JobManager {
	
	private static final Logger logger = LoggerFactory.getLogger(JobManager.class);
	
	@Autowired
	private TaskTasksetDao taskTasksetDao;	
	
	@Autowired
	private JobDao jobDao;	

	@Autowired
	private SubrequestDao subrequestDao;
	
	@Autowired
	private RequestDao requestDao;
	
	@Autowired
	private TaskDao taskDao;
	
	@Autowired
	private JobUtils jobUtils;	

	@Autowired
	private TaskUtils taskUtils;
	
	@Autowired
	private ProcessSingleThreadExecutor processSingleThreadExecutor;
	
	@Autowired
	private StorageSingleThreadExecutor storageSingleThreadExecutor;

	@Autowired
	private ApplicationContext applicationContext;

	
	public List<Job> createJobs(Request request, Subrequest subrequest, Library library){
		List<Job> jobList = new ArrayList<Job>();

		int tasksetId = request.getLibraryclass().getTasksetId();
		logger.trace("tasksetId - " + tasksetId);
		List<TaskTaskset> taskTasksetList = taskTasksetDao.findAllByTasksetId(tasksetId);
		for (Iterator<TaskTaskset> iterator = taskTasksetList.iterator(); iterator.hasNext();) {
			TaskTaskset taskTaskset = (TaskTaskset) iterator.next();
			
			Job job = new Job();
			Task nthTask = taskTaskset.getTask();
			logger.trace("nthTaskId in set - " + nthTask.getId());
			job.setTask(nthTask);
			// If a task contains prerequisite task that means its a derived one, for which the input library id needs to set by the prerequisite task at the time of its processing not at the time of job creation...
			// for eg., Mezz copy wont have a input library id upfront, which will be generated by the Mezz Transcoding job...
			if(taskTaskset.getPreTask() == null) {
				if(library != null) // For eg., restore requests if they decide to use taskset instead of tasks as right now, library will be null and this section is not needed anyway...
					job.setInputLibrary(library);
			}
			job.setSubrequest(subrequest);				
			job.setCreatedAt(LocalDateTime.now());
			job.setStatus(Status.queued);
			jobList.add(job);
		}
		
		return jobList;
	}

	
	//createJobsForRestore
	//createJobsForRerunIngest
//	public List<Job> createJobs(int requesttypeId, int libraryclassId, Subrequest request, Library library){
//		List<Job> jobList = new ArrayList<Job>();
//		int requestId = request.getId();
//
//		TaskOrTasksetDetails taskOrTasksetDetails = taskUtils.getTaskOrTasksetDetails(requesttypeId, libraryclassId);
//		int tasksetId = taskOrTasksetDetails.getTasksetId();
//		int taskId = taskOrTasksetDetails.getTaskId();
//
//		List<TaskTaskset> taskTasksetList = null;
//		if(tasksetId > 0) {
//			logger.trace("Its a taskset. tasksetId - " + tasksetId);
//			taskTasksetList = taskTasksetDao.findAllByTasksetId(tasksetId);
//			for (Iterator<TaskTaskset> iterator = taskTasksetList.iterator(); iterator.hasNext();) {
//				TaskTaskset taskTaskset = (TaskTaskset) iterator.next();
//				
//				Job job = new Job();
//				int nthTaskId = taskTaskset.getTaskId();
//				logger.trace("nthTaskId in set - " + nthTaskId);
//				job.setTaskId(nthTaskId);
//				// If a task contains prerequisite task that means its a derived one, for which the input library id needs to set by the prerequisite task...
//				// for eg., Mezz copy wont have a library id  upfront, which will be generated by the Mezz Transcoding job...
//				if(taskTaskset.getPreTaskId() == 0) {
//					if(library != null) // For eg., restore requests if they decide to use taskset instead of tasks as right now, library will be null and this section is not needed anyway...
//						job.setInputLibraryId(library.getLibraryId());
//				}
//				job.setSubrequestId(requestId);				
//				job.setCreatedAt(Calendar.getInstance().getTimeInMillis());
//				job.setStatusId(Status.QUEUED.getStatusId());
//				jobList.add(job);
//			}
//		}else if(taskId > 0){
//			Job job = new Job();
//			job.setTaskId(taskId);
//			job.setSubrequestId(requestId);				
//			job.setCreatedAt(Calendar.getInstance().getTimeInMillis());
//			job.setStatusId(Status.QUEUED.getStatusId());
//			jobList.add(job);
//		}
//		
//		return jobList;
//	}
	
//
//	
//	
//	public void processJobs() {
//		List<Job> storageJobList = new ArrayList<Job>();
//		
//		List<Job> jobList = jobDao.findAllByStatusIdOrderByJobId(Status.QUEUED.getStatusId());
//		for (Iterator<Job> iterator = jobList.iterator(); iterator.hasNext();) {
//			Job job = (Job) iterator.next();
//			logger.info("job - " + job.getId());
//			int taskId = job.getTaskId();
//			// check prerequisite jobs completion status
//			boolean isJobReadyToBeProcessed = isJobReadyToBeProcessed(job);
//			logger.info("isJobReadyToBeProcessed - " + isJobReadyToBeProcessed);
//			if(isJobReadyToBeProcessed) {
//				Task task = taskDao.findById(taskId).get();
//				int processId = task.getProcessId();
//				
//				if(processId > 0) { // a non-storage process job
//					logger.trace("process job");
//					ProcessJobManager_ThreadTask processJobManager_ThreadTask = applicationContext.getBean(ProcessJobManager_ThreadTask.class);
//					processJobManager_ThreadTask.setJob(job);
//					processJobManager_ThreadTask.setProcessId(processId);
//					processSingleThreadExecutor.getExecutor().execute(processJobManager_ThreadTask);
//				}else {
//					logger.trace("added to storagejob collection");
//					// all storage jobs need to be grouped for some optimisation...
//					storageJobList.add(job);
//				}
//			}
//		}
//		
//		StorageJobsManager_ThreadTask storageThreadTask = applicationContext.getBean(StorageJobsManager_ThreadTask.class);
//		storageThreadTask.setJobList(storageJobList);
//		storageSingleThreadExecutor.getExecutor().execute(storageThreadTask);
//	}
//
//	private boolean isJobReadyToBeProcessed(Job job) {
//		boolean isJobReadyToBeProcessed = true;
//		int subrequestId = job.getSubrequestId();
//		Subrequest subrequest = subrequestDao.findById(subrequestId).get(); // TODO : Cache the call...
//		Request request = requestDao.findById(subrequest.getRequestId()).get(); // TODO : Cache the call...
//		Job parentJob = jobUtils.getPrerequisiteJob(job, request.getRequesttypeId(), request.getLibraryclassId()); // Has the prerequisite job's status is complete?
//		if(parentJob != null) {
//			int parentJobStatusId = parentJob.getStatusId();
//			if(parentJobStatusId != Status.COMPLETED.getStatusId() && parentJobStatusId != Status.COMPLETED_WITH_FAILURE.getStatusId())
//				isJobReadyToBeProcessed = false;
//		}
//		
//		return isJobReadyToBeProcessed;
//	}
}
